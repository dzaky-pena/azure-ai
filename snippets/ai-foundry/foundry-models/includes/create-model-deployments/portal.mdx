---
---

[!INCLUDE [Header](intro)]

* An AI project connected to your Azure AI Foundry resource with the feature **Deploy models to Azure AI Foundry Models service** on.

  * You can follow the steps at [Configure Foundry Models service in my project](../../how-to/quickstart-ai-project.md#configure-the-project-to-use-foundry-models) in Azure AI Foundry.

## Add a model

You can add models to the Foundry Models endpoint using the following steps:

1. Go to **Model catalog** section in [Azure AI Foundry portal](https://ai.azure.com/explore/models).

2. Scroll to the model you're interested in and select it.

   <Frame>
      ![](/images/ai-foundry/foundry-models/media/add-model-deployments/models-search-and-deploy.gif)
   </Frame>
3. You can review the details of the model in the model card.

4. Select **Deploy**.

5. For model providers that require more terms of contract, you'll be asked to accept those terms. This is the case for Mistral models for instance. Accept the terms on those cases by selecting **Subscribe and deploy**.

   <Frame>
      ![](/images/ai-foundry/foundry-models/media/add-model-deployments/models-deploy-agree.png)
   </Frame>
6. You can configure the deployment settings at this time. By default, the deployment receives the name of the model you're deploying. The deployment name is used in the `model` parameter for request to route to this particular model deployment. This allows you to also configure specific names for your models when you attach specific configurations. For instance `o1-preview-safe` for a model with a strict content filter.

   <Tip>
   Each model can support different deployments types, providing different data residency or throughput guarantees. See [deployment types](../../concepts/deployment-types) for more details.
   </Tip>

5. We automatically select an Azure AI Foundry connection depending on your project. Use the **Customize** option to change the connection based on your needs. If you're deploying under the **Serverless API** deployment type, the models need to be available in the region of the Azure AI Foundry resource.
   
   <Frame>
      ![](/images/ai-foundry/foundry-models/media/add-model-deployments/models-deploy-customize.png)
   </Frame>
   <Tip>
   If the desired resource isn't listed, you might need to create a connection to it. See [Configure Azure AI Foundry Models in my project](../../how-to/configure-project-connection) in Azure AI Foundry portal.
   </Tip>

6. Select **Deploy**.

7. Once the deployment completes, the new model is listed in the page and it's ready to be used.

## Manage models

You can manage the existing model deployments in the resource using Azure AI Foundry portal.

1. Go to **Models + Endpoints** section in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).

2. Scroll to the connection to your Azure AI Foundry resource. Model deployments are grouped and displayed per connection.

   <Frame>
      ![](/images/ai-foundry/foundry-models/media/quickstart-ai-project/endpoints-ai-services-connection.png)
   </Frame>
3. You see a list of models available under each connection. Select the model deployment you're interested in.

4. **Edit** or **Delete** the deployment as needed.


## Test the deployment in the playground

You can interact with the new model in Azure AI Foundry portal using the playground:

<Note>
Playground is only available when working with AI projects in Azure AI Foundry. Create an AI project to get full access to all the capabilities in Azure AI Foundry.
</Note>

1. Go to **Playgrounds** section in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).

2. Depending on the type of model you deployed, select the playground needed. In this case we select **Chat playground**.

3. In the **Deployment** drop down, under **Setup** select the name of the model deployment you have created.

   <Frame>
      ![](/images/ai-foundry/foundry-models/media/add-model-deployments/playground-chat-models.png)
   </Frame>
4. Type your prompt and see the outputs.

5. Additionally, you can use **View code** so see details about how to access the model deployment programmatically.
