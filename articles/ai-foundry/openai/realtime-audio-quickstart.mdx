---
title: "How to use GPT-4o Realtime API for speech and audio with Azure OpenAI in Azure AI Foundry Models"
description: Learn how to use GPT-4o Realtime API for speech and audio with Azure OpenAI.
---

# GPT-4o Realtime API for speech and audio (Preview)

import FeaturePreview from '/snippets/ai-foundry/openai/includes/preview-feature.mdx'

<FeaturePreview />

Azure OpenAI GPT-4o Realtime API for speech and audio is part of the GPT-4o model family that supports low-latency, "speech in, speech out" conversational interactions. 

You can use the Realtime API via WebRTC or WebSocket to send audio input to the model and receive audio responses in real time. 

Follow the instructions in this article to get started with the Realtime API via WebSockets. Use the Realtime API via WebSockets in server-to-server scenarios where low latency isn't a requirement.

<Tip>
In most cases, we recommend using the [Realtime API via WebRTC](./how-to/realtime-audio-webrtc) for real-time audio streaming in client-side applications such as a web application or mobile app. WebRTC is designed for low-latency, real-time audio streaming and is the best choice for most use cases.
</Tip> 

## Supported models

The GPT 4o real-time models are available for global deployments.
- `gpt-4o-realtime-preview` (version `2024-12-17`)
- `gpt-4o-mini-realtime-preview` (version `2024-12-17`)

See the [models and versions documentation](./concepts/models.md#audio-models) for more information.

## API support

Support for the Realtime API was first added in API version `2024-10-01-preview` (retired). Use version `2025-04-01-preview` to access the latest Realtime API features. 
<Tabs>
<Tab title="Foundry portal">

import AzureAiFoundryPortalQuickstart from '/snippets/ai-foundry/openai/includes/realtime-portal.mdx'

<AzureAiFoundryPortalQuickstart />

</Tab>

<Tab title="JavaScript">

import JavascriptQuickstart from '/snippets/ai-foundry/openai/includes/realtime-javascript.mdx'

<JavascriptQuickstart />

</Tab>

<Tab title="Python">

import PythonQuickstart from '/snippets/ai-foundry/openai/includes/realtime-python.mdx'

<PythonQuickstart />

</Tab>

<Tab title="TypeScript">

import TypescriptQuickstart from '/snippets/ai-foundry/openai/includes/realtime-typescript.mdx'

<TypescriptQuickstart />

</Tab>
</Tabs>
## Related content

* Learn more about [How to use the Realtime API](./how-to/realtime-audio)
* See the [Realtime API reference](./realtime-audio-reference)
* Learn more about Azure OpenAI [quotas and limits](quotas-limits)
* Learn more about [Language and voice support for the Speech service](../../ai-services/speech-service/language-support)
