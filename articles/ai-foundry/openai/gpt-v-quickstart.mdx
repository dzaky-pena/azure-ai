---
title: "Quickstart: Use vision-enabled chats with the Azure OpenAI in Azure AI Foundry Models"
description: Use this article to get started using Azure OpenAI to deploy and use the GPT-4 Turbo with Vision model or other vision-enabled models. 
---

# Quickstart: Use images in your AI chats

Get started using images in your chats with Azure OpenAI in Azure AI Foundry Models.

<Info>
Extra usage fees might apply when using chat completion models with vision functionality.
</Info>

<Tab title="Foundry portal">

[!INCLUDE [Azure AI Foundry portal quickstart](includes/gpt-v-studio)]

</Tab>

<Tab title="REST API">

[!INCLUDE [REST API quickstart](includes/gpt-v-rest)]

</Tab>

<Tab title="Python">

[!INCLUDE [Python quickstart](includes/gpt-v-python)]

</Tab>

<Tab title="JavaScript">

[!INCLUDE [JavaScript quickstart](includes/gpt-v-javascript)]

</Tab>

<Tab title="TypeScript">

[!INCLUDE [TypeScript quickstart](includes/gpt-v-typescript)]

</Tab>

<Tab title="C#">

[!INCLUDE [.NET quickstart](includes/gpt-v-dotnet)]

</Tab>

## Related content

* [Get started with multimodal vision chat apps using Azure OpenAI AI App template](/azure/developer/ai/get-started-app-chat-vision?tabs=github-codespaces)
* Learn more about these APIs in the [Vision-enabled models how-to guide](./gpt-v-quickstart)
* [GPT-4 Turbo with Vision frequently asked questions](./faq.yml#gpt-4-turbo-with-vision)
* [GPT-4 Turbo with Vision API reference](https://aka.ms/gpt-v-api-ref)
