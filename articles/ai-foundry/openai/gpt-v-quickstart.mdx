---
title: "Quickstart: Use vision-enabled chats with the Azure OpenAI in Azure AI Foundry Models"
description: Use this article to get started using Azure OpenAI to deploy and use the GPT-4 Turbo with Vision model or other vision-enabled models. 
---

# Quickstart: Use images in your AI chats

Get started using images in your chats with Azure OpenAI in Azure AI Foundry Models.

<Info>
Extra usage fees might apply when using chat completion models with vision functionality.
</Info>
<Tabs>
<Tab title="Foundry portal">

import AzureAiFoundryPortalQuickstart from '/snippets/ai-foundry/openai/includes/gpt-v-studio.mdx'

<AzureAiFoundryPortalQuickstart />

</Tab>

<Tab title="REST API">

import RestApiQuickstart from '/snippets/ai-foundry/openai/includes/gpt-v-rest.mdx'

<RestApiQuickstart />

</Tab>

<Tab title="Python">

import PythonQuickstart from '/snippets/ai-foundry/openai/includes/gpt-v-python.mdx'

<PythonQuickstart />

</Tab>

<Tab title="JavaScript">

import JavascriptQuickstart from '/snippets/ai-foundry/openai/includes/gpt-v-javascript.mdx'

<JavascriptQuickstart />

</Tab>

<Tab title="TypeScript">

import TypescriptQuickstart from '/snippets/ai-foundry/openai/includes/gpt-v-typescript.mdx'

<TypescriptQuickstart />

</Tab>

<Tab title="C#">

import DotNetQuickstart from '/snippets/ai-foundry/openai/includes/gpt-v-dotnet.mdx'

<DotNetQuickstart />

</Tab>
</Tabs>
## Related content

* [Get started with multimodal vision chat apps using Azure OpenAI AI App template](/azure/developer/ai/get-started-app-chat-vision?tabs=github-codespaces)
* Learn more about these APIs in the [Vision-enabled models how-to guide](./gpt-v-quickstart)
* [GPT-4 Turbo with Vision frequently asked questions](./faq.yml#gpt-4-turbo-with-vision)
* [GPT-4 Turbo with Vision API reference](https://aka.ms/gpt-v-api-ref)
